from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
import chromedriver_autoinstaller
import pandas as pd
import time
import re
import json
import os

# âœ… ChromeDriver ìë™ ì„¤ì¹˜
chromedriver_autoinstaller.install()

# âœ… Selenium ì˜µì…˜ ì„¤ì •
options = Options()
options.add_argument("--headless")  # ë¸Œë¼ìš°ì € ì°½ ì—†ì´ ì‹¤í–‰
options.add_argument("--no-sandbox")
options.add_argument("--disable-dev-shm-usage")
options.add_argument("--disable-blink-features=AutomationControlled")
options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/134.0.0.0 Safari/537.36")

# âœ… WebDriver ì‹¤í–‰
service = Service()
driver = webdriver.Chrome(service=service, options=options)
driver.implicitly_wait(5)  # ğŸ”¥ ìš”ì†Œ ë¡œë”©ì„ ê¸°ë‹¤ë¦¬ëŠ” ì‹œê°„ ì„¤ì •

def load_json(filename):
    if os.path.exists(filename):
        with open(filename, "r", encoding="utf-8") as f:
            return json.load(f)
    else:
        print(f"ğŸš¨ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {filename}")
        return []

# âœ… í¬ë¡¤ë§í•  ì§€ì—­ ë¦¬ìŠ¤íŠ¸ (JSON íŒŒì¼ ë¡œë“œ)
locations = load_json("seoul_locations.json")

# âœ… ë°ì´í„° ì €ì¥ ë¦¬ìŠ¤íŠ¸
all_data = []
SCROLL_LIMIT = 100  # âœ… ìµœëŒ€ ìŠ¤í¬ë¡¤ ë‹¤ìš´ íšŸìˆ˜ ì„¤ì •

for location in locations:
    if location["êµ¬"] != "ì¢…ë¡œêµ¬":
        break
    print(f"ğŸ“Œ í¬ë¡¤ë§ ì¤‘: {location['êµ¬']} {location['ë™']}")

    # âœ… í•´ë‹¹ ë²•ì •ë™ ì½”ë“œë¡œ ê²€ìƒ‰ëœ ë„¤ì´ë²„ ë¶€ë™ì‚° í˜ì´ì§€ ì ‘ì†
    url = f"https://new.land.naver.com/houses?cortarNo={location['ë²•ì •ë™ì½”ë“œ']}"
    driver.get(url)
    time.sleep(3)

    # âœ… ìŠ¤í¬ë¡¤ ëŒ€ìƒ ìš”ì†Œ ì°¾ê¸° (`.item_list.item_list--article`)
    try:
        scroll_container = driver.find_element(By.CLASS_NAME, "item_list--article")
    except Exception as e:
        print(f"ğŸš¨ ìŠ¤í¬ë¡¤ ì»¨í…Œì´ë„ˆë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {e}")
        continue

    # âœ… ë§¤ë¬¼ ë¦¬ìŠ¤íŠ¸ ìŠ¤í¬ë¡¤í•˜ì—¬ ì¶”ê°€ ë§¤ë¬¼ ë¡œë“œ
    last_count = 0
    scroll_count = 0

    while scroll_count < SCROLL_LIMIT:
        # í˜„ì¬ ë¡œë“œëœ ë§¤ë¬¼ ê°œìˆ˜ í™•ì¸
        listings = driver.find_elements(By.CLASS_NAME, "item_link")
        current_count = len(listings)

        # ìŠ¤í¬ë¡¤ ì‹¤í–‰
        driver.execute_script("arguments[0].scrollTop = arguments[0].scrollHeight;", scroll_container)
        time.sleep(3)  # ğŸ”¥ ì¶©ë¶„í•œ ë¡œë”© ì‹œê°„ í™•ë³´

        # ìƒˆë¡œìš´ ë§¤ë¬¼ì´ ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸
        if current_count == last_count:
            print("ğŸš¨ ë” ì´ìƒ ë¡œë“œí•  ë§¤ë¬¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            break

        last_count = current_count
        scroll_count += 1
        print(f"ğŸ”½ ìŠ¤í¬ë¡¤ ë‹¤ìš´ {scroll_count}/{SCROLL_LIMIT} - í˜„ì¬ ë§¤ë¬¼ ê°œìˆ˜: {current_count}")

    # âœ… ë§¤ë¬¼ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
    listings = driver.find_elements(By.CLASS_NAME, "item_link")
    print(f"âœ… ì´ {len(listings)}ê°œì˜ ë§¤ë¬¼ ë°œê²¬")

    if not listings:
        print(f"ğŸš¨ {location['êµ¬']} {location['ë™']} - ë§¤ë¬¼ ì—†ìŒ")
        continue

    for listing in listings:
        try:
            listing.click()  # âœ… ë§¤ë¬¼ í´ë¦­
            time.sleep(2)  # âœ… ìƒì„¸ í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°

            # âœ… í˜„ì¬ URLì—ì„œ articleNo ì¶”ì¶œ
            current_url = driver.current_url
            match = re.search(r"articleNo=(\d+)", current_url)
            if not match:
                print("ğŸš¨ ë§¤ë¬¼ ë²ˆí˜¸(articleNo) ì¶”ì¶œ ì‹¤íŒ¨")
                continue

            article_no = match.group(1)
            detail_url = f"https://new.land.naver.com/houses?articleNo={article_no}"

            # âœ… ìƒì„¸ ì •ë³´ ì¶”ì¶œ
            try:
                ìœ í˜• = driver.find_element(By.CLASS_NAME, "type").text.strip()
            except:
                ìœ í˜• = ""

            try:
                ê±°ë˜ìœ í˜• = driver.find_element(By.XPATH, "//div[contains(@class, 'info_article_price')]/span[1]").text.strip()
            except:
                ê±°ë˜ìœ í˜• = ""

            try:
                ê°€ê²© = driver.find_element(By.XPATH, "//div[contains(@class, 'info_article_price')]//span[contains(@class, 'price')]").text.strip()
            except:
                ê°€ê²© = ""

            try:
                ì†Œì¬ì§€ = driver.find_element(By.XPATH, "//th[contains(text(), 'ì†Œì¬ì§€')]/following-sibling::td").text.strip()
            except:
                ì†Œì¬ì§€ = ""

            try:
                ë§¤ë¬¼íŠ¹ì§• = driver.find_element(By.XPATH, "//th[contains(text(), 'ë§¤ë¬¼íŠ¹ì§•')]/following-sibling::td").text.strip()
            except:
                ë§¤ë¬¼íŠ¹ì§• = ""

            try:
                ë©´ì  = driver.find_element(By.XPATH, "//th[contains(text(), 'ê³µê¸‰/ì „ìš©ë©´ì ')]/following-sibling::td").text.strip()
            except:
                ë©´ì  = ""

            try:
                ì¸µìˆ˜ = driver.find_element(By.XPATH, "//th[contains(text(), 'í•´ë‹¹ì¸µ/ì´ì¸µ')]/following-sibling::td").text.strip()
            except:
                ì¸µìˆ˜ = ""

            try:
                ë°©ìš•ì‹¤ìˆ˜ = driver.find_element(By.XPATH, "//th[contains(text(), 'ë°©ìˆ˜/ìš•ì‹¤ìˆ˜')]/following-sibling::td").text.strip()
            except:
                ë°©ìš•ì‹¤ìˆ˜ = ""

            try:
                ê´€ë¦¬ë¹„ = driver.find_element(By.XPATH, "//th[contains(text(), 'ê´€ë¦¬ë¹„')]/following-sibling::td").text.strip()
            except:
                ê´€ë¦¬ë¹„ = ""

            try:
                ì…ì£¼ê°€ëŠ¥ = driver.find_element(By.XPATH, "//th[contains(text(), 'ì…ì£¼ê°€ëŠ¥ì¼')]/following-sibling::td").text.strip()
            except:
                ì…ì£¼ê°€ëŠ¥ = ""

            try:
                ë°©í–¥ = driver.find_element(By.XPATH, "//th[contains(text(), 'ë°©í–¥')]/following-sibling::td").text.strip()
            except:
                ë°©í–¥ = ""

            # âœ… ë°ì´í„° ì €ì¥
            all_data.append({
                "ë§¤ë¬¼ë²ˆí˜¸": article_no,
                "êµ¬": location["êµ¬"],
                "ë™": location["ë™"],
                "ìœ í˜•": ìœ í˜•,
                "ê±°ë˜ìœ í˜•": ê±°ë˜ìœ í˜•,
                "ê°€ê²©": ê°€ê²©,
                "ì†Œì¬ì§€": ì†Œì¬ì§€,
                "ë§¤ë¬¼íŠ¹ì§•": ë§¤ë¬¼íŠ¹ì§•,
                "ê³µê¸‰/ì „ìš©ë©´ì ": ë©´ì ,
                "í•´ë‹¹ì¸µ/ì´ì¸µ": ì¸µìˆ˜,
                "ë°©ìˆ˜/ìš•ì‹¤ìˆ˜": ë°©ìš•ì‹¤ìˆ˜,
                "ê´€ë¦¬ë¹„": ê´€ë¦¬ë¹„,
                "ì…ì£¼ ê°€ëŠ¥ì¼": ì…ì£¼ê°€ëŠ¥,
                "ë°©í–¥": ë°©í–¥,
                "URL": detail_url
            })

            print(f"âœ… ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ: {ì†Œì¬ì§€} - {ê°€ê²©}")

            time.sleep(2)

        except Exception as e:
            print(f"ğŸš¨ ìƒì„¸ í˜ì´ì§€ ì´ë™ ì˜¤ë¥˜: {e}")

    print(f"ğŸ“Œ {location['êµ¬']} {location['ë™']} í¬ë¡¤ë§ ì™„ë£Œ! ì´ {len(all_data)}ê°œ ë§¤ë¬¼ ìˆ˜ì§‘.")

    # âœ… JSON íŒŒì¼ë¡œ ì €ì¥
if all_data:
    with open("naver_real_estate_details.json", "w", encoding="utf-8") as f:
        json.dump(all_data, f, ensure_ascii=False, indent=4)
    print("âœ… ëª¨ë“  ë§¤ë¬¼ ìƒì„¸ í¬ë¡¤ë§ ì™„ë£Œ! JSON íŒŒì¼ ì €ì¥ ì™„ë£Œ.")
else:
    print("ğŸš¨ í¬ë¡¤ë§ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. JSON íŒŒì¼ì„ ì €ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

# âœ… WebDriver ì¢…ë£Œ
driver.quit()
