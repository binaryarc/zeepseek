from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.common.action_chains import ActionChains
import chromedriver_autoinstaller
import pandas as pd
import time
import re
import json
import os
import random

# β… ChromeDriver μλ™ μ„¤μΉ
chromedriver_autoinstaller.install()

# β… λ‹¤μ–‘ν• User-Agent λ¦¬μ¤νΈ
user_agents = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/134.0.0.0 Safari/537.36",
    "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36",
]

# β… Selenium μµμ… μ„¤μ •
options = Options()
options.add_argument("--headless=new")  # β… μµμ‹  headless λ¨λ“ μ μ©
options.add_argument("--no-sandbox")
options.add_argument("--disable-dev-shm-usage")
options.add_argument("--disable-blink-features=AutomationControlled")
options.add_argument("--disable-gpu")  # β… GPU λΉ„ν™μ„±ν™” (λ λ”λ§ λ¬Έμ  λ°©μ§€)
options.add_argument("--disable-software-rasterizer")  # β… λ λ”λ§ λ¬Έμ  λ°©μ§€
options.add_argument("--log-level=3")  # β… λ¶ν•„μ”ν• λ΅κ·Έ μ¨κΈ°κΈ°
options.add_argument(f"user-agent={random.choice(user_agents)}")  # β… User-Agent λλ¤ μ μ©

# β… WebDriver μ‹¤ν–‰
service = Service()
driver = webdriver.Chrome(service=service, options=options)
driver.implicitly_wait(5)  # π”¥ μ”μ† λ΅λ”©μ„ κΈ°λ‹¤λ¦¬λ” μ‹κ°„ μ„¤μ •

# β… WebDriver νƒμ§€ λ°©μ§€ μ½”λ“ μ‹¤ν–‰
driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")

def load_json(filename):
    """κΈ°μ΅΄ JSON νμΌμ„ λ΅λ“ν•λ” ν•¨μ"""
    if os.path.exists(filename):
        with open(filename, "r", encoding="utf-8") as f:
            return json.load(f)
    else:
        return []

def save_data_to_json(filename, new_data):
    """μƒλ΅μ΄ λ°μ΄ν„°λ¥Ό κΈ°μ΅΄ JSON νμΌμ— μ¶”κ°€ν•λ” ν•¨μ"""
    existing_data = load_json(filename)  # κΈ°μ΅΄ λ°μ΄ν„° λ΅λ“
    existing_data.extend(new_data)  # μƒ λ°μ΄ν„° μ¶”κ°€
    with open(filename, "w", encoding="utf-8") as f:
        json.dump(existing_data, f, ensure_ascii=False, indent=4)
    print(f"β… JSON νμΌ μ—…λ°μ΄νΈ μ™„λ£: {filename} (μ΄ {len(existing_data)}κ°)")

def scroll_down_with_check(driver, scroll_container, max_scrolls=100):
    last_count = 0
    scroll_attempts = 0
    
    while scroll_attempts < max_scrolls:
        try:
            listings = driver.find_elements(By.CLASS_NAME, "item_link")
            current_count = len(listings)

            if current_count > last_count:  # β… μƒλ΅μ΄ λ§¤λ¬Όμ΄ λ΅λ“λμ—λ”μ§€ ν™•μΈ
                print(f"π”½ μ¤ν¬λ΅¤ {scroll_attempts+1}/{max_scrolls}: {current_count}κ° λ§¤λ¬Ό λ΅λ“λ¨")
                last_count = current_count
                scroll_attempts += 1
                driver.execute_script("arguments[0].scrollTo(0, arguments[0].scrollHeight);", scroll_container)
                time.sleep(random.uniform(3, 5))  # β… λλ¤ λ”λ μ΄
            else:
                print("π¨ λ” μ΄μƒ λ΅λ“ν•  λ§¤λ¬Όμ΄ μ—†μ")
                break
        except Exception as e:
            print(f"π¨ μ¤ν¬λ΅¤ μ¤λ¥ λ°μƒ: {e}")
            break

def extract_main_photo_url():
    """μƒμ„Έ μ •λ³΄ νμ΄μ§€ λ‚΄ λ©”μΈ μ‚¬μ§„ URL μ¶”μ¶"""
    try:
        main_photo_button = driver.find_element(By.CLASS_NAME, "main_photo_item")
        style_attribute = main_photo_button.get_attribute("style")
        match = re.search(r'url\("([^"]+)"\)', style_attribute)  # `url("...")` ν¨ν„΄μ—μ„ URL μ¶”μ¶
        if match:
            return match.group(1)
        return ""
    except:
        return None

# β… ν¬λ΅¤λ§ν•  μ§€μ—­ λ¦¬μ¤νΈ (JSON νμΌ λ΅λ“)
locations = load_json("seoul_locations.json")

# β… λ°μ΄ν„° μ €μ¥ λ¦¬μ¤νΈ
JSON_FILENAME = "naver_real_estate_details.json"

def get_random_user_agent():
    """λλ¤ User-Agent λ°ν™"""
    return random.choice(user_agents)

allowed_dongs = [
    "μ„μΈνΉλ³„μ‹ λ§ν¬κµ¬ κ³µλ•λ™",
    "μ„μΈνΉλ³„μ‹ λ§ν¬κµ¬ μ‹ κ³µλ•λ™",
    "μ„μΈνΉλ³„μ‹ λ§ν¬κµ¬ λ„ν™”λ™",
    "μ„μΈνΉλ³„μ‹ λ§ν¬κµ¬ μ©κ°•λ™",
    "μ„μΈνΉλ³„μ‹ λ§ν¬κµ¬ ν† μ •λ™",
    "μ„μΈνΉλ³„μ‹ λ§ν¬κµ¬ λ§ν¬λ™",
    "μ„μΈνΉλ³„μ‹ λ§ν¬κµ¬ λ€ν¥λ™",
    "μ„μΈνΉλ³„μ‹ λ§ν¬κµ¬ μ—Όλ¦¬λ™",
    "μ„μΈνΉλ³„μ‹ λ§ν¬κµ¬ λ…Έκ³ μ‚°λ™",
    "μ„μΈνΉλ³„μ‹ λ§ν¬κµ¬ μ‹ μλ™",
    "μ„μΈνΉλ³„μ‹ λ§ν¬κµ¬ ν„μ„λ™",
    "μ„μΈνΉλ³„μ‹ λ§ν¬κµ¬ κµ¬μλ™",
    "μ„μΈνΉλ³„μ‹ λ§ν¬κµ¬ μ°½μ „λ™",
    "μ„μΈνΉλ³„μ‹ λ§ν¬κµ¬ μƒμλ™",
    "μ„μΈνΉλ³„μ‹ λ§ν¬κµ¬ ν•μ¤‘λ™",
    "μ„μΈνΉλ³„μ‹ λ§ν¬κµ¬ μ‹ μ •λ™",
    "μ„μΈνΉλ³„μ‹ λ§ν¬κµ¬ λ‹ΉμΈλ™",
    "μ„μΈνΉλ³„μ‹ λ§ν¬κµ¬ μ„κµλ™",
    "μ„μΈνΉλ³„μ‹ λ§ν¬κµ¬ λ™κµλ™",
    "μ„μΈνΉλ³„μ‹ λ§ν¬κµ¬ ν•©μ •λ™",
    "μ„μΈνΉλ³„μ‹ λ§ν¬κµ¬ λ§μ›λ™",
    "μ„μΈνΉλ³„μ‹ λ§ν¬κµ¬ μ—°λ‚¨λ™"
]

for location in locations:
    if location['λ²•μ •λ™λ…'][:9] != "μ„μΈνΉλ³„μ‹ λ§ν¬κµ¬" or (location['λ²•μ •λ™λ…'] in allowed_dongs):
        continue
    print(f"π“ ν¬λ΅¤λ§ μ¤‘: {location['λ²•μ •λ™λ…']}")

    # β… λ§¤ μ”μ²­λ§λ‹¤ λλ¤ User-Agent μ μ©
    options.add_argument(f"user-agent={get_random_user_agent()}")
    driver = webdriver.Chrome(service=service, options=options)

    # β… ν•΄λ‹Ή λ²•μ •λ™ μ½”λ“λ΅ κ²€μƒ‰λ λ„¤μ΄λ²„ λ¶€λ™μ‚° νμ΄μ§€ μ ‘μ†
    url = f"https://new.land.naver.com/houses?cortarNo={location['λ²•μ •λ™μ½”λ“']}"
    driver.get(url)
    time.sleep(random.uniform(8, 10))  # β… λλ¤ λ”λ μ΄

    driver.refresh()
    time.sleep(random.uniform(8, 10))

    # β… λ§¤ λ™λ§λ‹¤ μ¤ν¬λ΅¤ μ»¨ν…μ΄λ„λ¥Ό λ‹¤μ‹ μ°Ύμ
    for attempt in range(3):  # π¨ μµλ€ 3λ² μ‹λ„ (μƒλ΅κ³ μΉ¨ ν¬ν•¨)
        try:
            scroll_container = driver.find_element(By.CLASS_NAME, "item_list--article")
            break  # β… μ¤ν¬λ΅¤ μ»¨ν…μ΄λ„λ¥Ό μ°Ύμ•μΌλ©΄ λ£¨ν”„ μΆ…λ£
        except:
            print(f"π¨ μ¤ν¬λ΅¤ μ»¨ν…μ΄λ„λ¥Ό μ°Ύμ„ μ μ—†μ, {attempt+1}λ²μ§Έ μ‹λ„ ν›„ μƒλ΅κ³ μΉ¨")
            driver.refresh()
            time.sleep(random.uniform(3, 6))

    scroll_down_with_check(driver, scroll_container)

    # β… λ§¤λ¬Ό λ¦¬μ¤νΈ κ°€μ Έμ¤κΈ°
    listings = driver.find_elements(By.CLASS_NAME, "item_link")
    print(f"β… μ΄ {len(listings)}κ°μ λ§¤λ¬Ό λ°κ²¬")

    if not listings:
        print(f"π¨ {location['λ²•μ •λ™λ…']} - λ§¤λ¬Ό μ—†μ")
        driver.quit()
        continue

    all_data = []  # β… λ™λ³„ λ°μ΄ν„° μ €μ¥
    i = 0
    for listing in listings:
        try:
            i += 1
            listing.click()
            time.sleep(random.uniform(3, 5))  # β… λλ¤ λ”λ μ΄

            #  μƒλ΅ μ—΄λ¦° νƒ­μ΄ μλ‹¤λ©΄ μλ™μΌλ΅ λ‹«κΈ°
            if len(driver.window_handles) > 1:
                print("π¨ μƒ νƒ­μ΄ κ°μ§€λ¨! λ¶ν•„μ”ν• νƒ­μ„ λ‹«μµλ‹λ‹¤.")
                main_window = driver.window_handles[0]  # μ›λ μ°½
                for handle in driver.window_handles[1:]:  # μƒ νƒ­λ“¤
                    driver.switch_to.window(handle)
                    driver.close()
                driver.switch_to.window(main_window)  # λ‹¤μ‹ μ›λ μ°½μΌλ΅ μ΄λ™

            current_url = driver.current_url
            match = re.search(r"articleNo=(\d+)", current_url)
            if not match:
                print("π¨ λ§¤λ¬Ό λ²νΈ(articleNo) μ¶”μ¶ μ‹¤ν¨")
                continue

            article_no = match.group(1)
            detail_url = f"https://new.land.naver.com/houses?articleNo={article_no}"

            def get_text(xpath):
                try:
                    return driver.find_element(By.XPATH, xpath).text.strip()
                except:
                    return ""

            data = {
                "λ§¤λ¬Όλ²νΈ": article_no,
                "λ§¤λ¬Όμ ν•" : driver.execute_script("return document.querySelector('.label--category')?.innerText || '';"),
                "κ±°λμ ν•": get_text("//div[contains(@class, 'info_article_price')]/span[1]"),
                "κ°€κ²©": get_text("//div[contains(@class, 'info_article_price')]//span[contains(@class, 'price')]"),
                "μ†μ¬μ§€": get_text("//th[contains(text(), 'μ†μ¬μ§€')]/following-sibling::td"),
                "λ§¤λ¬ΌνΉμ§•": get_text("//th[contains(text(), 'λ§¤λ¬ΌνΉμ§•')]/following-sibling::td"),
                "κ³µκΈ‰/μ „μ©λ©΄μ ": get_text("//th[contains(text(), 'κ³µκΈ‰/μ „μ©λ©΄μ ')]/following-sibling::td"),
                "ν•΄λ‹ΉμΈµ/μ΄μΈµ": get_text("//th[contains(text(), 'ν•΄λ‹ΉμΈµ/μ΄μΈµ')]/following-sibling::td"),
                "λ°©μ/μ•μ‹¤μ": get_text("//th[contains(text(), 'λ°©μ/μ•μ‹¤μ')]/following-sibling::td"),
                "κ΄€λ¦¬λΉ„": get_text("//th[contains(text(), 'κ΄€λ¦¬λΉ„')]/following-sibling::td"),
                "μ…μ£Ό κ°€λ¥μΌ": get_text("//th[contains(text(), 'μ…μ£Όκ°€λ¥μΌ')]/following-sibling::td"),
                "λ°©ν–¥": get_text("//th[contains(text(), 'λ°©ν–¥')]/following-sibling::td"),
                "URL": detail_url,
                "λ©”μΈμ‚¬μ§„": extract_main_photo_url()
            }

            all_data.append(data)
            print(f"β… μƒμ„Έ μ •λ³΄ μμ§‘ μ™„λ£: {data['μ†μ¬μ§€']} - {data['κ°€κ²©']}, {i}/{len(listings)}")
            time.sleep(random.uniform(2, 4))  

        except Exception as e:
            print(f"π¨ μƒμ„Έ νμ΄μ§€ μ΄λ™ μ¤λ¥: {e}")
            print(f"π¨ {location['λ²•μ •λ™λ…']} ν¬λ΅¤λ§ μ¤‘λ‹¨, λ‹¤μ λ™μΌλ΅ μ΄λ™")
            break  # β… ν•΄λ‹Ή λ™ ν¬λ΅¤λ§ μ¤‘λ‹¨ν•κ³  λ‹¤μ λ™μΌλ΅ μ΄λ™

    # β… λ™λ³„λ΅ JSON νμΌ μ €μ¥
    if all_data:
        save_data_to_json(JSON_FILENAME, all_data)

    print(f"π“ {location['λ²•μ •λ™λ…']} ν¬λ΅¤λ§ μ™„λ£!")

    driver.get(url)
    time.sleep(random.uniform(5, 10))  # β… λλ¤ λ”λ μ΄
    driver.quit()