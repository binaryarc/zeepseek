# 집시크 서비스의 데이터 수집, 전처리, 저장 과정 학습 기록

네이버 부동산 API를 활용하여 집시크 서비스의 데이터 수집, 전처리, 저장 과정을 학습하였습니다. 이를 통해 부동산 데이터를 다루는 전체적인 흐름과 필요한 기술 스택을 이해할 수 있었습니다.

### 데이터 수집 (Web Crawling & API Request)

📌 네이버 부동산 API 분석

- 네이버 부동산의 비공식 API를 활용하여 매물 데이터를 수집
- XHR 네트워크 요청을 분석하여 매물 정보가 포함된 API URL 확인

📌 API 요청 및 데이터 수집 과정

- requests 라이브러리를 사용하여 네이버 부동산 매물 데이터를 JSON 형식으로 가져옴
- 주요 요청 파라미터 분석 (지역 코드, 가격 범위, 면적, 거래 유형 등)
- User-Agent와 Referer 설정을 통한 웹사이트 차단 방지

### 데이터 전처리 (Preprocessing)

📌 데이터 필터링 및 정제

- JSON 데이터에서 불필요한 필드 제거 및 필요한 정보 추출
- 매물명, 가격, 면적, 위도/경도, 상세 링크 등 주요 필드 정리

📌 데이터 변환 및 정규화

- 가격 단위 변환 (억/만원 → 숫자로 변환)
- 면적 표기 변환 (평 → ㎡ 변환 가능성 고려)
- 좌표 데이터(위도/경도) 활용 가능하도록 정리

📌 데이터 오류 처리

- NULL 값 또는 데이터 누락된 항목 필터링
- 중복 매물 제거

### 데이터 저장 (Storage & Export)

📌 JSON 파일 저장

- 수집한 매물 데이터를 JSON 형식으로 저장하여 가독성 유지
- 데이터 백업 및 분석 시 활용 가능

📌 CSV 파일 저장

- Pandas를 활용하여 CSV 파일로 변환 및 저장
- 엑셀, 데이터베이스 등에 쉽게 로드 가능하도록 구조화

📌 데이터 활용을 위한 확장 가능성

- 데이터베이스(MySQL, MongoDB) 저장 가능
- 지도 서비스 연동을 위한 위도/경도 데이터 포함
- 추후 머신러닝 모델 학습을 위한 데이터 전처리 고려

# 🔎 학습한 주요 내용 정리

✅ 네이버 부동산 API 분석 및 요청 방식 학습
✅ 데이터 필터링, 변환, 정규화 과정 학습
✅ JSON & CSV 파일 저장 방식 이해 및 활용
✅ 부동산 데이터를 활용한 실용적인 서비스 개발 가능성 탐색

📌 이 학습 과정을 바탕으로 향후 데이터 분석, 시각화, 머신러닝 모델 학습 등에 적용할 수 있는 방법을 고민할 예정입니다.
